# Other important features not shown yet:
# * including other files for resource configuration?
# * including other files for `get` and `put`?
# * including other files for jobs as a whole?

resources:
# Resources work very similarly to Concourse, aside from we just always assume they're images to be
# run. This way we can avoid the additional step of adding a `resource_types` entry. Resources all
# expose a hook that can be called to trigger a "check" for a new version. This would somehow need
# to be customisable in a plugin - i.e. when a hook comes in.
- name: console-src
  image: dnab/git
  # Some options will have defaults that seem sensible:
  poll: true # Default
  poll_interval: 1m # Default
  # Options are string key to string value entries that configure a resource.
  options:
    # Whether or not options were required will have to be handled by the plugin, but there should
    # be a standard way to fail, and inform the user about what has happened in a plugin.
    repository: ${env.CONSOLE_SRC_GIT_URI}
    # Variables like this won't be stored in the pipeline remotely, the pipeline will be stored as
    # is, and resolved when it's running. This means all parameters could be treated as secrets.
    # All values will be treated as strings, so if a plugin needs some non-string configuration it
    # should handle the conversion itself.
    private_key: ${secrets.CONSOLE_SRC_PRIVATE_KEY}

- name: console-version
  image: dnab/semver
  # ...

- name: console-s3
  image: dnab/s3
  # ...

- name: email-notification
  image: dnab/sendgrid-notification
  options:
    apikey: ${secrets.SENDGRID_NOTIFICATION_APIKEY}

- name: slack-notification
  # Image is literally exactly the same as in Docker, if you want to specify a version then you can.
  image: dnab/slack-notification
  options:
    # These names are quite specific, but you would also be able to re-use values across different
    # resources, or in other places.
    webhook: ${secrets.SLACK_NOTIFICATION_WEBHOOK}

jobs:
- name: test-console
  description: |
    Run automated tests against the console codebase to ensure things are working as intended still
    after some changes have been made.
  tasks:
  - pull: console-src
    # Setting this to true will mean when a new version is found (either by the hook being called,
    # or the resource polling) it will trigger this task. There can be multiple triggers. A variable
    # will be added to the environment to say which resource triggered the job.
    trigger: true
  - pull: console-version
  - exec: test
    file: console-src/ci/tasks/test.yml
    input_mapping: { console: console-src }
  - push: console-s3
    params: { input: [ console-src ] }
    # Recover (again stealing some naming from Go) would allow you to deal with failure on a task.
    # This may be used to provide alternative actions (or basically perform any kind of task...)
    recover:
    - push: console-ftp
      params: { input: [ console-src ] }
    # Would `when` have to use some kind of expression language?
    # Would resources have to expose some kind of metadata?
    # Resources would have to have fairly strict naming requirements.
    # `when` would have to be able to be added to any task in a job.
    # `when` items would have an "or" relationship.
    when:
    - ${resources.console-src.branch} == 'master' # How do we express and/or relationships?
  # Deferred tasks run after all other tasks, and always run, regardless of the outcome, but can be
  # limited by using `when`. `on_success` and co don't make as much sense in this case, because you
  # have the status as a variable from the job. You can use that value and pass it into resources to
  # affect behaviour. This helps avoid duplication. You can also decide which tasks in `defer` run
  # with when still:
  defer:
  - parallel:
    - put: email-notification
      params: { status: "${job.status}" }
      when:
      - ${resources.console-src.branch} in ['master', 'feature/*'] && ${job.status} != 'success'
    - put: slack-notification
      params: { status: "${job.status}" }
